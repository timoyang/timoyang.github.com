<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[timo Blog]]></title>
  <link href="http://timoyang.github.com/atom.xml" rel="self"/>
  <link href="http://timoyang.github.com/"/>
  <updated>2013-01-19T11:31:40+08:00</updated>
  <id>http://timoyang.github.com/</id>
  <author>
    <name><![CDATA[timoyang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[末日]]></title>
    <link href="http://timoyang.github.com/blog/2012/12/21/mo-ri/"/>
    <updated>2012-12-21T23:35:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/12/21/mo-ri</id>
    <content type="html"><![CDATA[<p>  今天是2012-12-21，说好的世界末日，据说因为天气的原因延期了&#8230;&#8230;</p>

<p>  大家抱着一种欢天喜地的围观心态，等待着发生些什么，但是结局是，什么都没有发生。公司旁边的热干面依然以4块钱的原价在热卖，手机依然收到无数的告警短信，居然今天下午还有紧急版本要发布&#8230;&#8230;</p>

<p>  在一如既往的忙碌中，好像一切都是那么的理所当然。</p>

<p>  下班之后，走路回家，深南大道上堵得水泄不通，尽显疲态的白领们，快速地把自己挤进一辆公车。不知道大家是在忙着生活，还是忙着死去。</p>

<p>  &#8212;EOF&#8212;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[python multiprocessing 使用实例]]></title>
    <link href="http://timoyang.github.com/blog/2012/12/19/python-multiprocessing-shi-yong-shi-li/"/>
    <updated>2012-12-19T00:28:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/12/19/python-multiprocessing-shi-yong-shi-li</id>
    <content type="html"><![CDATA[<p>  随着web机器的不断增加，在最近的版本发布和配置发布过程中，真是伤透了脑筋，所以很迫切的对发布工具进行针对的优化。</p>

<p>  具体场景：集中从发布中心向所有机器推送版本和配置文件，涉及到大量的网络IO，之前的工具采用了比较传统的for循环ssh，在机器比较少的时候也能满足需求，但是现在机器多了起来，推送一次配置简直是个悲剧。考虑到每个对目标机器的推送的动作互相之间比较独立，所以考虑用多线程或多进程来推送配置。</p>

<p>  因为python的全局解析锁的存在，python的多线程只能跑在一个cpu上，为了充分利用现在性能强劲的多核cpu，考虑用multiprocessing模块来实现这个推送工具。</p>

<p>  关键的部分如下：</p>

<pre><code>import multiprocessing, time

def func(ips, results):
  while True:
    ip = ips.get()
    if ip is None:
      ips.task_done()
      break
    result = do_pub(ip)
    ips.task_done()
    results.put(result)
    time.sleep(1)

def pub():
  ips = multiprocessing.JoinableQueue()
  results = multiprocessing.JoinableQueue()

  for i in ip_list:
    ips.put(i)

  process_num = 10
  processes = []
  for i in range(10):
    processes.append(multiprocessing.Process(func, (ips, results,)))

  for i in processes:
    i.deamon = True
    i.start()

  ips.join()

  result_num = results.qsize()
  for i in result_num:
    print results.get()

if __name__ == '__main__':
  pub()
</code></pre>

<p>  实践了一下，目前看来效果很明显，但是实践的过程中，也发现很多值得折腾清楚的点，这些来几天把没搞请的折腾清楚，然后总结出来。</p>

<p>  &#8212;EOF&#8211;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[rsync 使用备忘]]></title>
    <link href="http://timoyang.github.com/blog/2012/12/11/rsync-shi-yong-bei-wang/"/>
    <updated>2012-12-11T22:49:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/12/11/rsync-shi-yong-bei-wang</id>
    <content type="html"><![CDATA[<p>  最近一段时间高频率地使用rysnc，由于之前对这个工具的使用并不是很熟练，导致使用的过程中各种问题，现在这里记录备忘一下，借此梳理一下对rsync的认识。</p>

<p>  rsync是一个Unix/Linux上的远程同步工具。通过rsync算法，以增量的方式同步文件，以减小文件的传输量。</p>

<p>  rsync的优势：</p>

<ul>
<li><p>可以以镜像的形式保存文件目录</p></li>
<li><p>可以通过ssh的方式来传输文件</p></li>
<li><p>增量式同步文件，减小同步传输量</p></li>
<li><p>保持文件的权限，时间，软硬链接</p></li>
</ul>


<p>  rsync的工作原理，coolshell这里有一篇详细介绍<a href="http://coolshell.com/articles/7425.html">rsync算法</a>,里面详细介绍了rysnc算法是怎样实现对文件的增量传输的。</p>

<h2>rysnc 使用</h2>

<pre><code>rsync SRC  DST #本地使用 SRC为源，DST为目标地址

rsync user@host:SRC DST  # 通过shell从host拉去SRC 到本地 DST
rsync SRC user@host:DST  # 通过sehll从本地SRC 推到 远程host DST

rsync user@host::SRC DST  # 通过rsync 服务端拉取SRC 到本地 DST
rsync SRC user@host::DST  #  推送本地SRC 到 远程rysnc 服务器 DST
</code></pre>

<p>  rsync 有两种工作模式，一种是C/S模式，这种方式需要启动rsyncd作为rysnc
  server端，另外一种是通过ssh的方式传输文件。</p>

<h2>具体使用场景</h2>

<ul>
<li><p>递归地同步某个文件夹</p>

<p>rsync -avrz -e &#8216;ssh -p 36000&#8217; SRC user@host:DST</p>

<p>-r 参数使rsync递归地对SRC的子目录进行同步</p>

<p>-z 对传输内容进行压缩</p>

<p>-e 指定使用的shell</p></li>
<li><p>只想检测有哪些文件不通，而不做同步操作</p>

<p>rsync -avrn -e &#8216;ssh -p 36000&#8217; SRC user@host:DST</p>

<p>-n 参数使rsync仅检测SRC 和远端DST的差异，而不传输文件</p></li>
<li><p>传输过程中需要保持被传输文件的属性</p>

<p>rsync -avrzpogt &#8216;ssh -p 36000&#8217; SRC user@host:DST</p>

<p>-p 保持文件的读写权限</p>

<p>-o 保持文件的拥有者属性</p>

<p>-g 保持文件测组属性</p>

<p>-t 保持文件的时间戳不变</p>

<p>(更正： man rsync 里面有这么一句：-a equals -rlptgoD
 所以上面关于保持传输文件属性的地方有点不对:P)</p></li>
<li><p>需要筛选同步的文件</p>

<p>rsync -avrz &#8211;exclude-from=FILE SRC user@host:DST</p>

<p>&#8211;exclude-from 指点rsync不同步FILE 文件，FILE 的路径为SRC的相对路径</p></li>
</ul>


<p>  注意在rsync中路径的写法， &#8216;/www/logs/&#8217; 表示同步/www/logs下面的内容到DST ，
  但是&#8217;/www/logs&#8217; 则是同步/www/logs这个文件夹到DST，就是在DST会建立相应的目录。</p>

<p>  这里记录了我遇到的一些应用场景，放在这里做个备忘。</p>

<p>  &#8212;EOF&#8212;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[进程管理工具-supervisor]]></title>
    <link href="http://timoyang.github.com/blog/2012/11/26/jin-cheng-guan-li-gong-ju-supervisor/"/>
    <updated>2012-11-26T22:37:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/11/26/jin-cheng-guan-li-gong-ju-supervisor</id>
    <content type="html"><![CDATA[<p>  最近折腾了一个jsonrpc的server来优化之前项目中的一些性能瓶颈，server需要作为守护进程一直在后台运行，传统的方式：</p>

<pre><code>$ nohup python server.py &amp;
</code></pre>

<p>  因为需要经常的重启server，通过nobup的方式非常不方便，所以想找一种更加方便的工具来管理进程。</p>

<p>  <a href="https://github.com/Supervisor/supervisor">supervisor</a>是一个python实现的进程管理工具，给自己的定义是：Supervisor
  is a client/server system that allows its users to control a number of
  processes on UNIX-like operating system.</p>

<h2>安装</h2>

<pre><code>sudo apt-get install supervisor

/etc/init.d/supervisor                 --superviosr server启动脚本
/etc/supervisor/supervisord.conf       --supervisor 主配置文件
supervisorctl                          --supervisor client控制命令
</code></pre>

<h2>配置</h2>

<p>  例如，我是server名为：rpc_server.py,
  需要在/etc/supervisor/supervisor.conf中添加如下配置</p>

<pre><code>[program:rpc_server]                   --进程名rpc_server
command = python rpc_server.py         --指定对应的执行命令
autostart = true                       --随着supervisord自动启动
stdout_logfile = /var/log/rpc_server.log   --指定std重定向
</code></pre>

<h2>操作</h2>

<pre><code>$ /etc/init.d/supervisor restart          --重启supervisord服务
$ supervisorctl status rpc_server         --查看rpc_server状态
$ supervisorctl start|stop|restart rpc_server     --实现对rpc_server进程的控制
</code></pre>

<p>  做一件事，并把这件事做好。非常不错的工具。</p>

<p>  &#8212;EOF&#8212;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[初试fabric]]></title>
    <link href="http://timoyang.github.com/blog/2012/11/25/chu-shi-fabric/"/>
    <updated>2012-11-25T01:25:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/11/25/chu-shi-fabric</id>
    <content type="html"><![CDATA[<p>  在日常工作中，我们总会遇到需要批量地到一堆机器上执行一些操作，以达到某些运维目的。大家基本都会包装一些自己的小工具去完成这类的工作，但是如果有成熟的工具，为啥不用呢？最近了解fabric这个工具，感觉挺有趣的，就拿来试了一下。:)</p>

<p>  <a href="http://fabfile.org">fabric</a> 给自己下的定义是：Simple, Pythonic remote
  execution and deployment. 基本已经告诉大家它是干啥的。</p>

<h2>安装</h2>

<pre><code>sudo apt-get install fabric
</code></pre>

<p>  如果是从git
  clone下来的源码编译安装的话，记得需要把python的bin路径添加到PATH里面，要不然执行fab命令的时候，会提示没有这个命令。</p>

<h2>实践</h2>

<p>  一个最常见的场景：我们需要批量的推送某个文件到目的机器，然后重启apache</p>

<p>  传统方法：</p>

<pre><code>scp xxx pub@x.x.x.x:/tmp/xxx
ssh x.x.x.x /etc/init.d/httpd restart
</code></pre>

<p>  fabric实现：</p>

<pre><code>$ cat fabfile

from fabric.api import sudo
from fabric.operation import put

def test():
  put('xxx', '/tmp/xxx')
  sudo('/etc/init.d/httpd restart')

$ fab -H x.x.x.x test
</code></pre>

<p>  这个一看好像fabric好像比传统的方式要麻烦很多，但是fabric是通过对paramiko进行了封装，ssh操作更加方便，将需要在远端执行的操作，书写起来就像是本地一样。</p>

<h3>常用配置</h3>

<pre><code>env.user              -- ssh登录到远端机器的用户
env.port              -- ssh绑定的端口
env.hosts             -- 远端机器ip列表
env.passwords         -- 以 'ip':'password' 的格式，保存相应password
env.roledefs          -- 角色定义 { 'web': ['x.x.x.x', 'y.y.y.y'], 'db': ['z.z.z.z']}
</code></pre>

<h3>常用命令</h3>

<pre><code>fab -H                -- 指定执行的host
fab -R                -- 指定执行的角色
fab -P -z             -- 指定并发执行的数目，默认是串行，-z指定具体个数
</code></pre>

<h3>常用命令</h3>

<pre><code>local()               -- 本地执行
run()                 -- 远程执行
put()                 -- 推送文件
get()                 -- 下载文件
sudo()                -- 执行远程sudo
</code></pre>

<p>  感觉这个工具用起来，相应的运维脚本清晰易读；区分角色这个功能非常贴心；混合本地操作和远程操作，书写方便；个人觉得比较好的一点是基于multiprocessing并发地执行，通常涉及到远程操作的时候，伴随这大量的网络IO等待，并发执行，大大提高执行的效率。非常Pythonic的工具。:)</p>

<p>  &#8211;EOF&#8211;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[web服务器扩容]]></title>
    <link href="http://timoyang.github.com/blog/2012/11/20/webfu-wu-qi-kuo-rong/"/>
    <updated>2012-11-20T23:55:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/11/20/webfu-wu-qi-kuo-rong</id>
    <content type="html"><![CDATA[<p>  随着公司近期的各种推广活动，负责的业务访问量突增很多，为了100%支撑业务的需求，最近对前端web机器做了一次扩容，各种折腾，收获很多。:)</p>

<p>  对一台web服务器的扩容大致包括：</p>

<ul>
<li><p>基础环境的搭建</p></li>
<li><p>应用的部署</p></li>
<li><p>网络策略的申请及验证</p></li>
<li><p>依赖的相关权限的申请及验证</p></li>
</ul>


<p>  当面对数量很多的服务器的时候，自动化已经不是一个要不要做的问题，而是怎样做得更好的问题。比较传统的做法是通过运维编写相应的部署脚本，推送到目的机器上执行，达到基础环境的部署目的，当然也有很多开源的自动化管理工具（如puppet），能将这些重复的体力劳动大大精简。</p>

<p>  一个成熟的运维团队，对于知识的积淀应该做到例行化，通过wiki或者bolg的方式保留下来，不但能在下次遇到同样问题的时候，迅速找到答案，还可以帮助刚加入团队的新人更快地对系统有比较全面的了解。</p>

<p>  在验证网络策略的过程中，发现之前是通过抽检的方式，随机去检查访问策略是否实施完成，这种方法不但耗时，而且效果非常不理想。为了达到偷懒的目的，自己折腾了一个验证的脚本，感觉效果还不错。：P
  想方设法地通过工具去“偷懒”，总能使日常的工作多了几分乐趣。</p>

<p>  &#8211;EOF&#8211;</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[像优秀的运维工程师那样思考]]></title>
    <link href="http://timoyang.github.com/blog/2012/11/15/xiang-you-xiu-de-yun-wei-gong-cheng-shi-na-yang-si-kao/"/>
    <updated>2012-11-15T21:54:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/11/15/xiang-you-xiu-de-yun-wei-gong-cheng-shi-na-yang-si-kao</id>
    <content type="html"><![CDATA[<p>  一转眼入职也3个多月了，多多少少对运维有了一些认识，总想找个时间梳理一下自己的一些认识，正好今天就把这篇流水帐作为第一篇自己的博客。</p>

<p>  作为一个刚毕业的学生，选择运维作为自己职业的方向或多或少会显得有点另类，在毕业找工作的那段时间几乎每个拿到我的简历的hr都会问我同一个问题“为什么你会想做运维？”。说来也是非常幸运，稀里糊涂地来到华工，稀里糊涂地加入knss，稀里糊涂地加入有米，一步一步见证了公司的成长，同时自己也伴随着公司飞速地成长。在整个过程中，深刻地认识到每一个位置上的人都是不可或缺的，各司其责，把自己的事情做得足够好，这样才能达到我们想去的地方。由于当时缺乏运维这块的人，所以我或多或少地开始接触运维这块知识，渐渐产生兴趣，想去折腾一下。毕业的时候正好有这么一个机会，于是我就来了。一个人来到深圳，开始自己的第一份工作。（：D故事背景有点长了）</p>

<p>  什么是运维？运维的核心职责就是在合理的成本的前提保证线上稳定运营，在技术上做好保障，给用户提供高品质的服务和体验。看似简单，但是真的实践起来可就没那么轻松了。如何对系统进行全面及时的监控，如何发现和解决系统的性能瓶颈，如何在单台机器故障的情况下保证服务的质量，如何做到在最低的成本的情况下提供最优的服务。。。</p>

<p>  优秀的运维工程师会怎样思考问题？</p>

<p>  当构建监控系统的时候，知道应该监控些什么以及如何监控，配合合适的告警策略，将监控系统作为了解自己系统的眼睛。通过监控系统，准确地掌握系统的真实情况。</p>

<p>  当面对性能瓶颈的时候，可以从系统层面和应用层面去全面分析，从根本上解决性能瓶颈。</p>

<p>  当需要批量处理事务的时候，熟练的运用脚本，优雅地将偷懒进行到极致。</p>

<p>  。。。</p>

<p>  由于我自己也刚刚开始，优秀的运维工程师到底怎样思考，我也不知道：P</p>

<p>  有能力保证自己认可的系统的稳定可用，并努力把它变得更好。这是我努力的方向。</p>

<p>  －－EOF－－</p>
]]></content>
  </entry>
  
</feed>
