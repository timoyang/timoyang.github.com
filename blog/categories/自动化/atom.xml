<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 自动化 | timo Blog]]></title>
  <link href="http://timoyang.github.com/blog/categories/自动化/atom.xml" rel="self"/>
  <link href="http://timoyang.github.com/"/>
  <updated>2013-02-28T22:34:25+08:00</updated>
  <id>http://timoyang.github.com/</id>
  <author>
    <name><![CDATA[timoyang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[python multiprocessing 使用实例]]></title>
    <link href="http://timoyang.github.com/blog/2012/12/19/python-multiprocessing-shi-yong-shi-li/"/>
    <updated>2012-12-19T00:28:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/12/19/python-multiprocessing-shi-yong-shi-li</id>
    <content type="html"><![CDATA[<p>  随着web机器的不断增加，在最近的版本发布和配置发布过程中，真是伤透了脑筋，所以很迫切的对发布工具进行针对的优化。</p>

<p>  具体场景：集中从发布中心向所有机器推送版本和配置文件，涉及到大量的网络IO，之前的工具采用了比较传统的for循环ssh，在机器比较少的时候也能满足需求，但是现在机器多了起来，推送一次配置简直是个悲剧。考虑到每个对目标机器的推送的动作互相之间比较独立，所以考虑用多线程或多进程来推送配置。</p>

<p>  因为python的全局解析锁的存在，python的多线程只能跑在一个cpu上，为了充分利用现在性能强劲的多核cpu，考虑用multiprocessing模块来实现这个推送工具。</p>

<p>  关键的部分如下：</p>

<pre><code>import multiprocessing, time

def func(ips, results):
  while True:
    ip = ips.get()
    if ip is None:
      ips.task_done()
      break
    result = do_pub(ip)
    ips.task_done()
    results.put(result)
    time.sleep(1)

def pub():
  ips = multiprocessing.JoinableQueue()
  results = multiprocessing.JoinableQueue()

  for i in ip_list:
    ips.put(i)

  process_num = 10
  processes = []
  for i in range(10):
    processes.append(multiprocessing.Process(func, (ips, results,)))

  for i in processes:
    i.deamon = True
    i.start()

  ips.join()

  result_num = results.qsize()
  for i in result_num:
    print results.get()

if __name__ == '__main__':
  pub()
</code></pre>

<p>  实践了一下，目前看来效果很明显，但是实践的过程中，也发现很多值得折腾清楚的点，这些来几天把没搞请的折腾清楚，然后总结出来。</p>

<p>  ---EOF--</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[进程管理工具-supervisor]]></title>
    <link href="http://timoyang.github.com/blog/2012/11/26/jin-cheng-guan-li-gong-ju-supervisor/"/>
    <updated>2012-11-26T22:37:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/11/26/jin-cheng-guan-li-gong-ju-supervisor</id>
    <content type="html"><![CDATA[<p>  最近折腾了一个jsonrpc的server来优化之前项目中的一些性能瓶颈，server需要作为守护进程一直在后台运行，传统的方式：</p>

<pre><code>$ nohup python server.py &amp;
</code></pre>

<p>  因为需要经常的重启server，通过nobup的方式非常不方便，所以想找一种更加方便的工具来管理进程。</p>

<p>  <a href="https://github.com/Supervisor/supervisor">supervisor</a>是一个python实现的进程管理工具，给自己的定义是：Supervisor
  is a client/server system that allows its users to control a number of
  processes on UNIX-like operating system.</p>

<h2>安装</h2>

<pre><code>sudo apt-get install supervisor

/etc/init.d/supervisor                 --superviosr server启动脚本
/etc/supervisor/supervisord.conf       --supervisor 主配置文件
supervisorctl                          --supervisor client控制命令
</code></pre>

<h2>配置</h2>

<p>  例如，我是server名为：rpc_server.py,
  需要在/etc/supervisor/supervisor.conf中添加如下配置</p>

<pre><code>[program:rpc_server]                   --进程名rpc_server
command = python rpc_server.py         --指定对应的执行命令
autostart = true                       --随着supervisord自动启动
stdout_logfile = /var/log/rpc_server.log   --指定std重定向
</code></pre>

<h2>操作</h2>

<pre><code>$ /etc/init.d/supervisor restart          --重启supervisord服务
$ supervisorctl status rpc_server         --查看rpc_server状态
$ supervisorctl start|stop|restart rpc_server     --实现对rpc_server进程的控制
</code></pre>

<p>  做一件事，并把这件事做好。非常不错的工具。</p>

<p>  ---EOF---</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[初试fabric]]></title>
    <link href="http://timoyang.github.com/blog/2012/11/25/chu-shi-fabric/"/>
    <updated>2012-11-25T01:25:00+08:00</updated>
    <id>http://timoyang.github.com/blog/2012/11/25/chu-shi-fabric</id>
    <content type="html"><![CDATA[<p>  在日常工作中，我们总会遇到需要批量地到一堆机器上执行一些操作，以达到某些运维目的。大家基本都会包装一些自己的小工具去完成这类的工作，但是如果有成熟的工具，为啥不用呢？最近了解fabric这个工具，感觉挺有趣的，就拿来试了一下。:)</p>

<p>  <a href="http://fabfile.org">fabric</a> 给自己下的定义是：Simple, Pythonic remote
  execution and deployment. 基本已经告诉大家它是干啥的。</p>

<h2>安装</h2>

<pre><code>sudo apt-get install fabric
</code></pre>

<p>  如果是从git
  clone下来的源码编译安装的话，记得需要把python的bin路径添加到PATH里面，要不然执行fab命令的时候，会提示没有这个命令。</p>

<h2>实践</h2>

<p>  一个最常见的场景：我们需要批量的推送某个文件到目的机器，然后重启apache</p>

<p>  传统方法：</p>

<pre><code>scp xxx pub@x.x.x.x:/tmp/xxx
ssh x.x.x.x /etc/init.d/httpd restart
</code></pre>

<p>  fabric实现：</p>

<pre><code>$ cat fabfile

from fabric.api import sudo
from fabric.operation import put

def test():
  put('xxx', '/tmp/xxx')
  sudo('/etc/init.d/httpd restart')

$ fab -H x.x.x.x test
</code></pre>

<p>  这个一看好像fabric好像比传统的方式要麻烦很多，但是fabric是通过对paramiko进行了封装，ssh操作更加方便，将需要在远端执行的操作，书写起来就像是本地一样。</p>

<h3>常用配置</h3>

<pre><code>env.user              -- ssh登录到远端机器的用户
env.port              -- ssh绑定的端口
env.hosts             -- 远端机器ip列表
env.passwords         -- 以 'ip':'password' 的格式，保存相应password
env.roledefs          -- 角色定义 { 'web': ['x.x.x.x', 'y.y.y.y'], 'db': ['z.z.z.z']}
</code></pre>

<h3>常用命令</h3>

<pre><code>fab -H                -- 指定执行的host
fab -R                -- 指定执行的角色
fab -P -z             -- 指定并发执行的数目，默认是串行，-z指定具体个数
</code></pre>

<h3>常用命令</h3>

<pre><code>local()               -- 本地执行
run()                 -- 远程执行
put()                 -- 推送文件
get()                 -- 下载文件
sudo()                -- 执行远程sudo
</code></pre>

<p>  感觉这个工具用起来，相应的运维脚本清晰易读；区分角色这个功能非常贴心；混合本地操作和远程操作，书写方便；个人觉得比较好的一点是基于multiprocessing并发地执行，通常涉及到远程操作的时候，伴随这大量的网络IO等待，并发执行，大大提高执行的效率。非常Pythonic的工具。:)</p>

<p>  --EOF--</p>
]]></content>
  </entry>
  
</feed>
